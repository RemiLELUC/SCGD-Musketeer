{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ZO-Ridge Regression\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from models import linearReg\n",
    "from simus import run_ols\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simu_block(seed,n_samples,n_features,puiss,block_size,noise):\n",
    "    np.random.seed(seed)\n",
    "    X = np.zeros((n_samples,n_features))\n",
    "    for j in range(n_features//block_size):\n",
    "        X_j = np.random.normal(scale=(j+1)**(-puiss),size=(n_samples,block_size))\n",
    "        X[:,j*block_size:(j+1)*block_size] = X_j\n",
    "    # shuffle columns of X\n",
    "    idx = np.random.permutation(n_features)\n",
    "    X[:, :] = X[:, idx]\n",
    "    ground_truth = np.random.uniform(low=-1,high=1,size=n_features)\n",
    "    y = X@ground_truth\n",
    "    if noise > 0.0:\n",
    "        y += np.random.normal(scale=noise, size=y.shape)\n",
    "    return X, y, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "n_features = 250\n",
    "# Simulate data for regression\n",
    "seed=0\n",
    "#uiss=5\n",
    "puiss=10\n",
    "noise=0.01\n",
    "block_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,coeff=simu_block(seed=seed,n_samples=n_samples,n_features=n_features,\n",
    "                     puiss=puiss,block_size=block_size,noise=noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute true solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ùúÜ = 1/n_samples          #regularization parameter\n",
    "G = ((X.T)@X)/n_samples  # Gram matrix\n",
    "A = G + ùúÜ*np.eye(n_features)\n",
    "B = ((X.T)@y)/n_samples\n",
    "ridge = np.linalg.solve(a=A ,b=B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_opt = np.sum((y-X.dot(ridge))**2)/(2*n_samples)\n",
    "reg_opt = (ùúÜ/2) * sum(ridge**2)\n",
    "loss_opt = data_opt + reg_opt\n",
    "print('data_opt:',data_opt)\n",
    "print('reg_opt :',reg_opt)\n",
    "print(loss_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linearReg(X=X,y=y,ùúÜ=ùúÜ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.loss(batch=np.arange(n_samples),w=ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.loss(batch=np.arange(n_samples),w=np.zeros(n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(200)  # number of passes over coordinates          \n",
    "a = 1          # numerator of learning rate\n",
    "t0 = 10\n",
    "alpha_power = 1 # power in the learning rate\n",
    "gamma = 1       # numerator in gradient factor smoothing\n",
    "mu_power = 1    # power in the gradient factor smoothing\n",
    "verbose = False # to display information\n",
    "N_exp = 20     # number of experiments\n",
    "fixed=False\n",
    "eta = 0.5\n",
    "#fixed = True\n",
    "batch_size = 1\n",
    "T = int(np.sqrt(n_features)) # size of exploration\n",
    "print('T=  ',T)\n",
    "print('ùúÜ=  ',ùúÜ)\n",
    "\n",
    "print('T=  ',T)\n",
    "print('ùúÜ=  ',ùúÜ)\n",
    "print('eta=',eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run different ZO methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full gradient estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,loss_full = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='full',N_exp=N_exp,N=N,\n",
    "                        T=None,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                        fixed=None,eta=None,importance=None,gains=None,verbose=False)\n",
    "l_ful = np.mean(loss_full,axis=0)\n",
    "std_ful = np.std(loss_full,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform coordinate sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,loss_uni = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='uni',N_exp=N_exp,N=N,\n",
    "                       T=None,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                      fixed=None,eta=None,importance=None,gains=None,verbose=False)\n",
    "l_uni = np.mean(loss_uni,axis=0)\n",
    "std_uni = np.std(loss_uni,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Musketeer biased (with different gains: Average, Absolute Value, Square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,loss_mus_avg = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='mus',N_exp=N_exp,N=N,\n",
    "                           T=T,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                           fixed=fixed,eta=eta,importance=False,gains='avg',\n",
    "                           verbose=False)\n",
    "l_avg = np.mean(loss_mus_avg,axis=0)\n",
    "std_avg = np.std(loss_mus_avg,axis=0)\n",
    "\n",
    "_,_,loss_mus_abs = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='mus',N_exp=N_exp,N=N,\n",
    "                           T=T,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                           fixed=fixed,eta=eta,importance=False,gains='abs',\n",
    "                           verbose=False)\n",
    "l_abs = np.mean(loss_mus_abs,axis=0)\n",
    "std_abs = np.std(loss_mus_abs,axis=0)\n",
    "\n",
    "_,_,loss_mus_sqr = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='mus',N_exp=N_exp,N=N,\n",
    "                           T=T,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                           fixed=fixed,eta=eta,importance=False,gains='square',\n",
    "                           verbose=False)\n",
    "l_sqr = np.mean(loss_mus_sqr,axis=0)\n",
    "std_sqr = np.std(loss_mus_sqr,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian smoothing estimate (Nesterov-Spokoiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,loss_nes = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='nes',N_exp=N_exp,N=N,\n",
    "                       T=T,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                       fixed=fixed,eta=eta,importance=False,gains='avg',\n",
    "                       verbose=False)\n",
    "l_nes = np.mean(loss_nes,axis=0)\n",
    "std_nes = np.std(loss_nes,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('loss_ful_ridge_puiss10.npy',loss_full)\n",
    "#np.save('loss_uni_ridge_puiss10.npy',loss_uni)\n",
    "#np.save('loss_avg_ridge_puiss10.npy',loss_mus_avg)\n",
    "#np.save('loss_abs_ridge_puiss10.npy',loss_mus_abs)\n",
    "#np.save('loss_sqr_ridge_puiss10.npy',loss_mus_sqr)\n",
    "#np.save('loss_nes_ridge_puiss10.npy',loss_nes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Musketeer -Importance Sampling (IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,loss_mus_avg_is = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,\n",
    "                       method='mus',N_exp=N_exp,N=N,\n",
    "                       T=T,gamma=gamma,mu_power=mu_power,a=a,alpha_power=alpha_power,\n",
    "                       fixed=fixed,eta=eta,importance=True,gains='avg',\n",
    "                       verbose=False)\n",
    "l_avg_is = np.mean(loss_mus_avg_is,axis=0)\n",
    "\n",
    "\n",
    "_,_,loss_mus_abs_is = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,\n",
    "                       method='mus',N_exp=N_exp,N=N,\n",
    "                       T=T,gamma=gamma,mu_power=mu_power,a=a,alpha_power=alpha_power,\n",
    "                       fixed=fixed,eta=eta,importance=True,gains='abs',\n",
    "                       verbose=False)\n",
    "l_abs_is = np.mean(loss_mus_abs_is,axis=0)\n",
    "\n",
    "\n",
    "_,_,loss_mus_sqr_is = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,\n",
    "                       method='mus',N_exp=N_exp,N=N,\n",
    "                       T=T,gamma=gamma,mu_power=mu_power,a=a,alpha_power=alpha_power,\n",
    "                       fixed=fixed,eta=eta,importance=True,gains='square',\n",
    "                       verbose=False)\n",
    "l_sqr_is = np.mean(loss_mus_sqr_is,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments in different settings (Appendix E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(200)  # number of passes over coordinates          \n",
    "a = 1          # numerator of learning rate\n",
    "t0 = 10\n",
    "alpha_power = 1 # power in the learning rate\n",
    "gamma = 1       # numerator in gradient factor smoothing\n",
    "mu_power = 1    # power in the gradient factor smoothing\n",
    "verbose = False # to display information\n",
    "N_exp = 20     # number of experiments\n",
    "fixed=False\n",
    "eta = 0.5\n",
    "batch_size = 1\n",
    "\n",
    "seed=0\n",
    "puiss=5\n",
    "noise=0.01\n",
    "block_size=10\n",
    "for n_samples in [1000,2000,5000]:\n",
    "    for n_features in [20,50,100,200]:\n",
    "        print('n = ',n_samples)\n",
    "        print('p = ',n_features)\n",
    "        T = int(np.sqrt(n_features)) # size of exploration\n",
    "        # Generate data for regression\n",
    "        X,y,coeff=simu_block(seed=seed,n_samples=n_samples,n_features=n_features,\n",
    "                     puiss=puiss,block_size=block_size,noise=noise)\n",
    "        # Compute true solution\n",
    "        ùúÜ = 1/n_samples          #regularization parameter\n",
    "        G = ((X.T)@X)/n_samples  # Gram matrix\n",
    "        A = G + ùúÜ*np.eye(n_features)\n",
    "        B = ((X.T)@y)/n_samples\n",
    "        ridge = np.linalg.solve(a=A ,b=B)\n",
    "        data_opt = np.sum((y-X.dot(ridge))**2)/(2*n_samples)\n",
    "        reg_opt = (ùúÜ/2) * sum(ridge**2)\n",
    "        loss_opt = data_opt + reg_opt\n",
    "        # Run simulation with different ZO methods for regression\n",
    "        _,_,loss_full = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='full',N_exp=N_exp,N=N,\n",
    "                        T=None,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                        fixed=None,eta=None,importance=None,gains=None,verbose=False)\n",
    "        _,_,loss_uni = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='uni',N_exp=N_exp,N=N,\n",
    "                       T=None,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                      fixed=None,eta=None,importance=None,gains=None,verbose=False)\n",
    "        _,_,loss_avg = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='mus',N_exp=N_exp,N=N,\n",
    "                           T=T,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                           fixed=fixed,eta=eta,importance=True,gains='avg',\n",
    "                           verbose=False)\n",
    "        _,_,loss_abs = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='mus',N_exp=N_exp,N=N,\n",
    "                                   T=T,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                                   fixed=fixed,eta=eta,importance=True,gains='abs',\n",
    "                                   verbose=False)\n",
    "        _,_,loss_sqr = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='mus',N_exp=N_exp,N=N,\n",
    "                                   T=T,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                                   fixed=fixed,eta=eta,importance=True,gains='square',\n",
    "                                   verbose=False)\n",
    "        _,_,loss_nes = run_ols(X=X,y=y,ùúÜ=ùúÜ,batch_size=batch_size,method='nes',N_exp=N_exp,N=N,\n",
    "                       T=T,gamma=gamma,mu_power=mu_power,a=a,t0=t0,alpha_power=alpha_power,\n",
    "                       fixed=fixed,eta=eta,importance=False,gains='avg',\n",
    "                       verbose=False)\n",
    "        #np.save('loss_ful_ridge_n{}_p{}.npy'.format(n_samples,n_features),loss_full-loss_opt)\n",
    "        #np.save('loss_uni_ridge_n{}_p{}.npy'.format(n_samples,n_features),loss_uni-loss_opt)\n",
    "        #np.save('loss_nes_ridge_n{}_p{}.npy'.format(n_samples,n_features),loss_nes-loss_opt)\n",
    "        #np.save('loss_avg_is_ridge_n{}_p{}.npy'.format(n_samples,n_features),loss_avg-loss_opt)\n",
    "        #np.save('loss_sqr_is_ridge_n{}_p{}.npy'.format(n_samples,n_features),loss_sqr-loss_opt)\n",
    "        #np.save('loss_abs_is_ridge_n{}_p{}.npy'.format(n_samples,n_features),loss_abs-loss_opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
